# -*- coding: utf-8 -*-
"""
Created on Mon Jan 15 00:20:48 2018

@author: saurabh
"""


import pandas as pd
import numpy as np


amazon = pd.read_csv("../assets/train.csv")

amazon.head()


amazon.isnull().sum()

amazon.iloc[:,1:].corr()


import seaborn as sns
sns.heatmap(amazon.corr())



import seaborn as sns
import matplotlib.pyplot as plt
%matplotlib inline

amazon.iloc[:,1:].corr()


from sklearn.tree import DecisionTreeClassifier
from sklearn.pipeline import make_pipeline
from sklearn.ensemble import BaggingClassifier
from sklearn.preprocessing import StandardScaler

X = amazon[amazon.columns[1:].tolist()]
y = amazon["ACTION"]
print(X.shape)

tr = DecisionTreeClassifier(max_depth=None)

model = make_pipeline(StandardScaler(with_mean=False),BaggingClassifier(tr))

model.fit(X,y)

test = pd.read_csv("../assets/test.csv")
sample = pd.read_csv("../assets/sampleSubmission.csv")

test.isnull().sum()

X_test = test[test.columns[1:].tolist()]

X.shape

X_test.shape

amazon.ACTION.value_counts()

predictions = model.predict(X_test)
sample['Action'] = predictions
sample.to_csv('../results/bagging_dt.csv', index=False)

model.get_params().keys()

from sklearn.grid_search import GridSearchCV

params = {
    'baggingclassifier__n_estimators':[50,100,250,500],
    
}



gs = GridSearchCV(model, params, cv=5, verbose=1, n_jobs=-1,scoring="roc_auc")
gs.fit(X, y)

predictions = gs.predict(X_test)
sample['Action'] = predictions
sample.to_csv('../results/bagging_dt_gs.csv', index=False)

from sklearn.cross_validation import cross_val_score, StratifiedKFold

cv = StratifiedKFold(y, n_folds=5,shuffle=True)

def score(model, name):
    s = cross_val_score(model, X, y, cv=cv,scoring="roc_auc")
    print "{} Score:\t{:0.3} Â± {:0.3}".format(name, s.mean().round(3), s.std().round(3))

#Import our ensembles
from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, GradientBoostingClassifier


rf = RandomForestClassifier(class_weight='balanced')

#Let's fit our X and y
rf.fit(X,y)


for a,b in zip(test.columns[1:].tolist(), rf.feature_importances_):
    print a, b

#Let's look at the cross val score of our Random Forest
score(rf, "Random Forest Classifier")

#Initialize adaboost, fit and let's check the feature importances like we did for Random Forest Classifier
ada = AdaBoostClassifier()
ada.fit(X,y)

for a,b in zip(test.columns[1:].tolist(), ada.feature_importances_):
    print a, b

#Let's look at the cross val score of our AdaBoost
score(ada, "Adaptive Boosting Classifier")

#Lastly, let's do this for the gradient boosting classifier
gb = GradientBoostingClassifier()
gb.fit(X,y)

for a,b in zip(test.columns[1:].tolist(), gb.feature_importances_):
    print a, b

score(gb, "Gradient Boosting Classifier")

predictions = rf.predict(X_test)
sample['Action'] = predictions
sample.to_csv('../results/rf.csv', index=False)

params = {'n_estimators':[3, 5, 10, 50],
          'criterion': ['gini', 'entropy'],
          'max_depth': [3, 5, 10, 20],
          'min_samples_split': [2,5],
          'class_weight':[None, 'balanced']}


gsrf = GridSearchCV(rf,params, n_jobs=-1,cv=cv,scoring="roc_auc")
gsrf.fit(X, y)

predictions = gsrf.predict(X_test)
sample['Action'] = predictions
sample.to_csv('../results/gs_rf.csv', index=False)
